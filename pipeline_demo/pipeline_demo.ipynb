{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMaPP Text Classification Pipeline\n",
    "\n",
    "This document provides a quick intro to the basic functionality of the pipeline.\n",
    "\n",
    "Goals: \n",
    "- Make training of supervised models for text classification easier for lab Members\n",
    "- Abstracted enough to take away tedious and repetitive tasks\n",
    "- But light enough to be modifiable and useful for specific use-cases\n",
    "\n",
    "What does it provide:\n",
    "- Quickly load data from common SMaPP formats\n",
    "- Easily build a pipeline that selects best algorithm, tuning parameters and featureset from common choices with reasonable defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/smappnyu/smapp_text_classifier.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smapp_text_classifier.data import DataSet\n",
    "from smapp_text_classifier.models import TextClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n",
    "logging.getLogger(\"gensim\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clinton_2016.csv    \u001b[1m\u001b[36membedding_models\u001b[m\u001b[m    pipeline_demo.ipynb\n",
      "clinton_2016.json   \u001b[1m\u001b[36mfeature_cache\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>773692075699306496</td>\n",
       "      <td>725302089048453124</td>\n",
       "      <td>RT @CNN: Singer Stevie Nicks is backing Hillar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>786581360672735232</td>\n",
       "      <td>753594430330900481</td>\n",
       "      <td>RT @Italians4Trump: Hillary Supporters Attack ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>775873669725843456</td>\n",
       "      <td>1452015206</td>\n",
       "      <td>RT @HillaryClinton: How pay-to-play works:\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>757926635404300292</td>\n",
       "      <td>550488178</td>\n",
       "      <td>one thing i know for sure is that Leslie Knope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>742758704165093376</td>\n",
       "      <td>2910845500</td>\n",
       "      <td>RT @HillaryClinton: Trump's rhetoric is shamef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label            tweet_id             user_id  \\\n",
       "0   Neutral  773692075699306496  725302089048453124   \n",
       "1  Negative  786581360672735232  753594430330900481   \n",
       "2  Positive  775873669725843456          1452015206   \n",
       "3  Positive  757926635404300292           550488178   \n",
       "4  Positive  742758704165093376          2910845500   \n",
       "\n",
       "                                                text  \n",
       "0  RT @CNN: Singer Stevie Nicks is backing Hillar...  \n",
       "1  RT @Italians4Trump: Hillary Supporters Attack ...  \n",
       "2  RT @HillaryClinton: How pay-to-play works:\\n\\n...  \n",
       "3  one thing i know for sure is that Leslie Knope...  \n",
       "4  RT @HillaryClinton: Trump's rhetoric is shamef...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clinton = pd.read_csv('clinton_2016.csv')\n",
    "df_clinton.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': {...},\n",
      " 'contributors': None,\n",
      " 'coordinates': None,\n",
      " 'created_at': 'Thu Sep 08 01:19:00 +0000 2016',\n",
      " 'entities': {...},\n",
      " 'extended_entities': {...},\n",
      " 'favorite_count': 0,\n",
      " 'favorited': False,\n",
      " 'filter_level': 'low',\n",
      " 'geo': None,\n",
      " 'id': 773692075699306496,\n",
      " 'id_str': '773692075699306496',\n",
      " 'in_reply_to_screen_name': None,\n",
      " 'in_reply_to_status_id': None,\n",
      " 'in_reply_to_status_id_str': None,\n",
      " 'in_reply_to_user_id': None,\n",
      " 'in_reply_to_user_id_str': None,\n",
      " 'is_quote_status': False,\n",
      " 'lang': 'en',\n",
      " 'place': None,\n",
      " 'possibly_sensitive': False,\n",
      " 'random_number': 0.3559609594276685,\n",
      " 'retweet_count': 0,\n",
      " 'retweeted': False,\n",
      " 'retweeted_status': {...},\n",
      " 'source': '<a href=\"https://roundteam.co\" rel=\"nofollow\">RoundTeam</a>',\n",
      " 'stance': 'Neutral',\n",
      " 'text': 'RT @CNN: Singer Stevie Nicks is backing Hillary Clinton, predicting '\n",
      "         'a \"landslide\" in November https://t.co/JE4KdZjzci '\n",
      "         'https://t.co/TZkHCD69â€¦',\n",
      " 'timestamp': {...},\n",
      " 'timestamp_ms': '1473297540007',\n",
      " 'truncated': False,\n",
      " 'user': {...}}\n"
     ]
    }
   ],
   "source": [
    "with open('clinton_2016.json') as infile:\n",
    "    pprint(json.loads(next(infile)), depth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Standardizing the Data\n",
    "\n",
    "Data can come as json or in tabular form. Only requirement is one column/field containing text and one containing a label. We can specify a tokenizer that is used for bag-of-words features (and to determine word boundaries for bag-of-character features). The tokenizer can be any function that maps a string to a list of tokens (e.g. `'This is a sentence' -> ['this', 'is', 'a', 'sentence']`). Here we use a tokenizer that was specifically developed for tweets. Here you could also add lemmatizatio or other desired transformations of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataSet` class allows the classification pipeline that we will use later to access all relevant information about the dataset. It is a light wrapper around a pandas dataframe that implements a few basic functions. The class can be instantiated with data from different formats: Files (tabular format, json format) or `pandas.DataFrame` objects.\n",
    "\n",
    "Importing a csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(input_='clinton_2016.csv', name='clinton', \n",
    "                  field_mapping={'label': 'label', 'text': 'text'}, # change this\n",
    "                  tokenizer=tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing a json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(input_='clinton_2016.json', name='clinton', \n",
    "                  field_mapping={'label': 'stance', 'text': 'text'},\n",
    "                  tokenizer=tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataSet(input_=df_clinton, name='clinton',\n",
    "                  field_mapping={'label': 'label', 'text': 'text'},\n",
    "                  tokenizer=tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing data that is already split into train/test. Note that the dataframes could also be files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_clinton.iloc[:700]\n",
    "df_test = df_clinton.iloc[701:]\n",
    "dataset = DataSet(train_input=df_train, test_input=df_test, name='clinton',\n",
    "                  field_mapping={'label': 'label', 'text': 'text'},\n",
    "                  tokenizer=tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The init method of `DataSet` does the following:\n",
    "- Transform to a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @CNN: Singer Stevie Nicks is backing Hillar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>RT @Italians4Trump: Hillary Supporters Attack ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @HillaryClinton: How pay-to-play works:\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>one thing i know for sure is that Leslie Knope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @HillaryClinton: Trump's rhetoric is shamef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0   Neutral  RT @CNN: Singer Stevie Nicks is backing Hillar...\n",
       "1  Negative  RT @Italians4Trump: Hillary Supporters Attack ...\n",
       "2  Positive  RT @HillaryClinton: How pay-to-play works:\\n\\n...\n",
       "3  Positive  one thing i know for sure is that Leslie Knope...\n",
       "4  Positive  RT @HillaryClinton: Trump's rhetoric is shamef..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split into training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "print(f'Train rows: {dataset.train_idxs[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test rows: [700, 701, 702, 703, 704, 705, 706, 707, 708, 709]\n"
     ]
    }
   ],
   "source": [
    "print(f'Test rows: {dataset.test_idxs[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Positive</td>\n",
       "      <td>RT @DorothyKidd1: Hillary Clinton draws surpri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Hillary Clinton sucks, but not like Monica Lew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @TIME: State Dept. reopens Hillary Clinton ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>Donald Trump, Hillary Clinton win Washington p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>RT @MacFarlaneNews: #Breaking:  Parents of two...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "700  Positive  RT @DorothyKidd1: Hillary Clinton draws surpri...\n",
       "701  Negative  Hillary Clinton sucks, but not like Monica Lew...\n",
       "702   Neutral  RT @TIME: State Dept. reopens Hillary Clinton ...\n",
       "703   Neutral  Donald Trump, Hillary Clinton win Washington p...\n",
       "704   Neutral  RT @MacFarlaneNews: #Breaking:  Parents of two..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Neutral\n",
       "1    Negative\n",
       "2    Positive\n",
       "3    Positive\n",
       "4    Positive\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_labels('train')[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a text pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ngram_range'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-53f67fdf97c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      \u001b[0mmax_n_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecompute_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mngram_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                      embedding_model=('twitter', \n\u001b[0m\u001b[1;32m      6\u001b[0m                                       'embedding_models/twitter/text_sample_2013to2016_gensim_200.model'))\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ngram_range'"
     ]
    }
   ],
   "source": [
    "clf = TextClassifier(dataset=dataset, algorithm='svm', \n",
    "                     feature_set='char_ngrams',\n",
    "                     max_n_features=10000, recompute_features=True,\n",
    "                     ngram_range = (1, 20),\n",
    "                     embedding_model=('twitter', \n",
    "                                      'embedding_models/twitter/text_sample_2013to2016_gensim_200.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls feature_cache/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TextClassifier(dataset=dataset, algorithm='elasticnet', feature_set='word_ngrams',\n",
    "                     max_n_features=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls feature_cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If precomputed features exist the pipeline re-uses them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TextClassifier(dataset=dataset, algorithm='elasticnet', feature_set='char_ngrams',\n",
    "                      max_n_features=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can also force recomputation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TextClassifier(dataset=dataset, algorithm='elasticnet', feature_set='char_ngrams',\n",
    "                      max_n_features=20000, recompute_features=True)\n",
    "# Method to see the selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main functionality is the building of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.pipeline.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And reasonable default parameters for Randomized Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This pipeline can be tuned using standard scikit-learn functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = RandomizedSearchCV(clf.pipeline, param_distributions=clf.params,\n",
    "                        n_iter=5, cv=3, n_jobs=8, scoring='accuracy', \n",
    "                        iid=True, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.get_texts('train')\n",
    "y = dataset.get_labels('train')\n",
    "CV = CV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tuning_params = CV.best_estimator_.get_params()\n",
    "print(f'Best n_gram range: {best_tuning_params[\"vectorize__ngram_range\"]}')\n",
    "print(f'Best l1_ratio (elastic net): {best_tuning_params[\"clf__l1_ratio\"]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(CV.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validating accross multiple Algorithms and Feature sets\n",
    "\n",
    "We can use a simple loop to check the performance of different algorithms. So far the following four are implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['random_forest', 'elasticnet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These feature sets are available (note that if you use `embeddings` you need to provide a gensim embedding model as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = ['embeddings', 'char_ngrams', 'word_ngrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algorithm in algorithms:\n",
    "    for feature_set in feature_sets:\n",
    "        logging.info(f'Fitting {algorithm} with {feature_set}')\n",
    "        \n",
    "        clf = TextClassifier(\n",
    "            dataset=dataset, algorithm=algorithm, feature_set=feature_set, \n",
    "            max_n_features=1e4, \n",
    "            embedding_model=('twitter', \n",
    "                             'embedding_models/twitter/text_sample_2013to2016_gensim_200.model')\n",
    "        )\n",
    "        \n",
    "        logging.info(f'Cross validating {algorithm} on {feature_set}')\n",
    "        CV = RandomizedSearchCV(clf.pipeline,\n",
    "                        param_distributions=clf.params,\n",
    "                        n_iter=10, cv=3, n_jobs=8,\n",
    "                        scoring='f1', iid=True)\n",
    "        X = dataset.get_texts('train')\n",
    "        y = dataset.get_labels('train')\n",
    "        CV = CV.fit(X, y)\n",
    "        \n",
    "        y_valid = dataset.get_labels('test')\n",
    "        X_valid = dataset.get_texts('test')\n",
    "        y_pred = CV.predict(X_valid)\n",
    "        score = round(accuracy_score(y_true=y_valid, y_pred=y_pred), 3)\n",
    "        logging.info(f'Best score for {algorithm} with {feature_set} on test set: {score}')\n",
    "        \n",
    "        best_t_params = CV.best_estimator_.get_params()\n",
    "        logging.info(f'Best feature_set: '\n",
    "                     f'\\n\\tngram_range: {best_t_params[\"vectorize__ngram_range\"]}'\n",
    "                     f'\\n\\tpooling_method: {best_t_params[\"vectorize__pooling_method\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
